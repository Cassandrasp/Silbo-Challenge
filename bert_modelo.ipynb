{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHuggingface BERT Model: dccuchile/bert-base-spanish-wwm-uncased\\nhttps://huggingface.co/dccuchile/bert-base-spanish-wwm-uncased\\n\\nNecessary installations: Python, Pandas, Numpy, Sklearn, PyTorch, transformers, TrainingArguments, tensorflow, spacy, \\npython -m spacy download es_core_news_sm\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Huggingface BERT Model: dccuchile/bert-base-spanish-wwm-uncased\n",
    "https://huggingface.co/dccuchile/bert-base-spanish-wwm-uncased\n",
    "\n",
    "Necessary installations: Python, Pandas, Numpy, Sklearn, PyTorch, transformers, TrainingArguments, tensorflow, spacy, \n",
    "python -m spacy download es_core_news_sm\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                input  intent\n",
      "0                      Quisiera comprar una camiseta.       1\n",
      "1                     Me gustaría pedir una camiseta.       1\n",
      "2                        Necesito una camiseta nueva.       1\n",
      "3                     Quiero una camiseta de algodón.       1\n",
      "4        Estoy buscando una camiseta en talla grande.       1\n",
      "5           Deseo comprar una camiseta con estampado.       1\n",
      "6            ¿Puedo pedir una camiseta en color azul?       1\n",
      "7            Necesitaría una camiseta de manga corta.       1\n",
      "8         Estoy interesado en una camiseta deportiva.       1\n",
      "9            Quiero comprar una camiseta para correr.       1\n",
      "10           Me gustaría adquirir una camiseta negra.       1\n",
      "11                Quisiera una camiseta sin etiqueta.       1\n",
      "12              Necesito una camiseta para un regalo.       1\n",
      "13         Deseo pedir una camiseta en talla mediana.       1\n",
      "14              ¿Podría tener una camiseta en oferta?       1\n",
      "15       Estoy buscando una camiseta con cuello en V.       1\n",
      "16                 Quiero una camiseta personalizada.       1\n",
      "17            Me gustaría una camiseta blanca básica.       1\n",
      "18      Quisiera ordenar una camiseta para el verano.       1\n",
      "19      Necesito una camiseta resistente al desgaste.       1\n",
      "20         ¿De qué material está hecho esta camiseta?       2\n",
      "21               ¿Cuál es el precio de esta camiseta?       2\n",
      "22            ¿Tienen esta camiseta en otros colores?       2\n",
      "23   ¿Esta camiseta está disponible en talla pequeña?       2\n",
      "24  ¿Pueden decirme más sobre el diseño de esta ca...       2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/icm_dataset.csv')\n",
    "print(df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_texts, test_texts, train_val_labels, test_labels = train_test_split(df['input'], df['intent'], test_size=0.1)  # Reserving 10% for testing\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_val_texts, train_val_labels, test_size=0.2)  # Split remaining 90% into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encodes labels: train, valuation and test\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "val_labels_encoded = label_encoder.transform(val_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\", do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=128, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(train_labels_encoded))\n",
    "val_dataset = TensorDataset(val_encodings['input_ids'], val_encodings['attention_mask'], torch.tensor(val_labels_encoded))\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(test_labels_encoded))\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "num_labels = len(set(train_labels_encoded))\n",
    "\n",
    "# Cargar el modelo BERT preentrenado de hugging\n",
    "model = BertForSequenceClassification.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "model.train()\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "# Guardar las clases de label_encoder despues de entrenar\n",
    "np.save('label_encoder_classes.npy', label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predicted_labels = torch.argmax(logits, dim=1)\n",
    "            predictions.extend(predicted_labels.numpy())\n",
    "            true_labels.extend(labels.numpy())\n",
    "\n",
    "    predictions = np.array(predictions)  # Convertir a array de NumPy\n",
    "    true_labels = np.array(true_labels)  # Convertir a array de NumPy\n",
    "\n",
    "    accuracy = (predictions == true_labels).mean()\n",
    "    return accuracy\n",
    "\n",
    "def predict_single_text(text):\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_label_idx = torch.argmax(logits, dim=1).item()\n",
    "    predicted_label = label_encoder.classes_[predicted_label_idx]\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9027777777777778\n",
      "Test Accuracy: 0.925\n",
      "Predicted Label: 2\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de evaluación sobre el conjunto de validación\n",
    "val_accuracy = evaluate_model(model, val_loader)\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "# Ejemplo de evaluación sobre el conjunto de prueba\n",
    "test_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "# Ejemplo de predicción sobre un texto individual\n",
    "new_text = \"Quiero información de este pantalon\"\n",
    "predicted_label = predict_single_text(new_text)\n",
    "print(f'Predicted Label: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
