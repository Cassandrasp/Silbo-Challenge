{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHuggingface BERT Model: dccuchile/bert-base-spanish-wwm-uncased\\nhttps://huggingface.co/dccuchile/bert-base-spanish-wwm-uncased\\n\\nNecessary installations: Python, Pandas, Numpy, Sklearn, PyTorch, transformers, TrainingArguments, tensorflow, spacy, \\npython -m spacy download es_core_news_sm\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Huggingface BERT Model: dccuchile/bert-base-spanish-wwm-uncased\n",
    "https://huggingface.co/dccuchile/bert-base-spanish-wwm-uncased\n",
    "\n",
    "Necessary installations: Python, Pandas, Numpy, Sklearn, PyTorch, transformers, TrainingArguments, tensorflow, spacy, \n",
    "python -m spacy download es_core_news_sm\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                input  intent\n",
      "0                      Quisiera comprar una camiseta.       1\n",
      "1                     Me gustaría pedir una camiseta.       1\n",
      "2                        Necesito una camiseta nueva.       1\n",
      "3                     Quiero una camiseta de algodón.       1\n",
      "4        Estoy buscando una camiseta en talla grande.       1\n",
      "5           Deseo comprar una camiseta con estampado.       1\n",
      "6            ¿Puedo pedir una camiseta en color azul?       1\n",
      "7            Necesitaría una camiseta de manga corta.       1\n",
      "8         Estoy interesado en una camiseta deportiva.       1\n",
      "9            Quiero comprar una camiseta para correr.       1\n",
      "10           Me gustaría adquirir una camiseta negra.       1\n",
      "11                Quisiera una camiseta sin etiqueta.       1\n",
      "12              Necesito una camiseta para un regalo.       1\n",
      "13         Deseo pedir una camiseta en talla mediana.       1\n",
      "14              ¿Podría tener una camiseta en oferta?       1\n",
      "15       Estoy buscando una camiseta con cuello en V.       1\n",
      "16                 Quiero una camiseta personalizada.       1\n",
      "17            Me gustaría una camiseta blanca básica.       1\n",
      "18      Quisiera ordenar una camiseta para el verano.       1\n",
      "19      Necesito una camiseta resistente al desgaste.       1\n",
      "20         ¿De qué material está hecho esta camiseta?       2\n",
      "21               ¿Cuál es el precio de esta camiseta?       2\n",
      "22            ¿Tienen esta camiseta en otros colores?       2\n",
      "23   ¿Esta camiseta está disponible en talla pequeña?       2\n",
      "24  ¿Pueden decirme más sobre el diseño de esta ca...       2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/icm_dataset.csv')\n",
    "print(df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('¿', 'PUNCT'), ('Cómo', 'PRON'), ('puedo', 'AUX'), ('cambiar', 'VERB'), ('mi', 'DET'), ('contraseña', 'NOUN'), ('?', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "# Parts of Speech (POS)\n",
    "import spacy\n",
    "\n",
    "# Carga modelo de Spanish NLP \n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def get_pos_tags(text):\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "    pos_tags = [(token.text, token.pos_) for token in doc]  # Extract each word and its POS tag \n",
    "    return pos_tags\n",
    "\n",
    "# ejemplo\n",
    "sentence = \"¿Cómo puedo cambiar mi contraseña?\"\n",
    "pos_tags = get_pos_tags(sentence)\n",
    "print(pos_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply POS tagging to a column of df (no sé si mejora el rendimiento del modelo todavia, podemos studiarlo...)\n",
    "df['pos_tags'] = df['input'].apply(get_pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>intent</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quisiera comprar una camiseta.</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Quisiera, VERB), (comprar, VERB), (una, DET)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Me gustaría pedir una camiseta.</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Me, PRON), (gustaría, VERB), (pedir, VERB), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Necesito una camiseta nueva.</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Necesito, VERB), (una, DET), (camiseta, NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quiero una camiseta de algodón.</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Quiero, VERB), (una, DET), (camiseta, NOUN),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Estoy buscando una camiseta en talla grande.</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Estoy, AUX), (buscando, VERB), (una, DET), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input  intent  \\\n",
       "0                Quisiera comprar una camiseta.       1   \n",
       "1               Me gustaría pedir una camiseta.       1   \n",
       "2                  Necesito una camiseta nueva.       1   \n",
       "3               Quiero una camiseta de algodón.       1   \n",
       "4  Estoy buscando una camiseta en talla grande.       1   \n",
       "\n",
       "                                            pos_tags  \n",
       "0  [(Quisiera, VERB), (comprar, VERB), (una, DET)...  \n",
       "1  [(Me, PRON), (gustaría, VERB), (pedir, VERB), ...  \n",
       "2  [(Necesito, VERB), (una, DET), (camiseta, NOUN...  \n",
       "3  [(Quiero, VERB), (una, DET), (camiseta, NOUN),...  \n",
       "4  [(Estoy, AUX), (buscando, VERB), (una, DET), (...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['intent'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_texts, test_texts, train_val_labels, test_labels = train_test_split(df['input'], df['intent'], test_size=0.1)  # Reserving 10% for testing\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_val_texts, train_val_labels, test_size=0.2)  # Split remaining 90% into training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos el **tokenizador de BERT** junto con \"dccuchile/bert-base-spanish-wwm-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encodes labels: train, valuation and test\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "val_labels_encoded = label_encoder.transform(val_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"val_encodings = tokenizer.encode_plus(\\n    list(val_texts),\\n    add_special_tokens=True,\\n    truncation=True,\\n    padding=True,\\n    max_length=128,\\n    return_attention_mask=True,\\n    return_tensors='pt'  # 'pt' indica que queremos tensores de PyTorch como salida\\n)\\n\\ntest_encodings = tokenizer.encode_plus(\\n    list(test_texts),\\n    add_special_tokens=True,\\n    truncation=True,\\n    padding=True,\\n    max_length=128,\\n    return_attention_mask=True,\\n    return_tensors='pt'  # 'pt' indica que queremos tensores de PyTorch como salida\\n)\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# PRUEBO NUEVO TOKENIZADOR BERT\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\", do_lower_case=False)\n",
    "#tokenizer = AutoTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased')\n",
    "\n",
    "'''train_encodings = tokenizer.encode_plus(\n",
    "    list(train_texts),\n",
    "    add_special_tokens=True,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'  # 'pt' indica que queremos tensores de PyTorch como salida\n",
    ")'''\n",
    "\n",
    "'''# Extraer los tensores de entrada y máscaras de atención del resultado\n",
    "input_ids = train_encodings['input_ids']\n",
    "attention_mask = train_encodings['attention_mask']'''\n",
    "\n",
    "'''val_encodings = tokenizer.encode_plus(\n",
    "    list(val_texts),\n",
    "    add_special_tokens=True,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'  # 'pt' indica que queremos tensores de PyTorch como salida\n",
    ")\n",
    "\n",
    "test_encodings = tokenizer.encode_plus(\n",
    "    list(test_texts),\n",
    "    add_special_tokens=True,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'  # 'pt' indica que queremos tensores de PyTorch como salida\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") OTRO TOKENIZADOR que probé\n",
    "\n",
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=128, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(train_labels_encoded))\n",
    "val_dataset = TensorDataset(val_encodings['input_ids'], val_encodings['attention_mask'], torch.tensor(val_labels_encoded))\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(test_labels_encoded))\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "num_labels = len(set(train_labels_encoded))\n",
    "\n",
    "# Cargar el modelo BERT preentrenado de hugging\n",
    "model = BertForSequenceClassification.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\", num_labels=num_labels)\n",
    "#model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_encoder.classes_)) OTRO MODELO que probé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "model.train()\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predicted_labels = torch.argmax(logits, dim=1)\n",
    "            predictions.extend(predicted_labels.numpy())\n",
    "            true_labels.extend(labels.numpy())\n",
    "\n",
    "    predictions = np.array(predictions)  # Convertir a array de NumPy\n",
    "    true_labels = np.array(true_labels)  # Convertir a array de NumPy\n",
    "\n",
    "    accuracy = (predictions == true_labels).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_text(text):\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_label_idx = torch.argmax(logits, dim=1).item()\n",
    "    predicted_label = label_encoder.classes_[predicted_label_idx]\n",
    "    return predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8873239436619719\n",
      "Test Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de evaluación sobre el conjunto de validación\n",
    "val_accuracy = evaluate_model(model, val_loader)\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "# Ejemplo de evaluación sobre el conjunto de prueba\n",
    "test_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 2\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de predicción sobre un texto individual\n",
    "new_text = \"Quiero información de este pantalon por favor\"\n",
    "predicted_label = predict_single_text(new_text)\n",
    "print(f'Predicted Label: {predicted_label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matriz de confusión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predicted_labels = torch.argmax(logits, dim=1)\n",
    "            predictions.extend(predicted_labels.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return true_labels, predictions\n",
    "\n",
    "def print_cm(true_labels, predictions, label_names):\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    print(\"Matriz de confusión:\")\n",
    "    print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[91  2  0]\n",
      " [ 4 89  5]\n",
      " [ 0  3 88]]\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusión de TRAIN\n",
    "true_labels, predictions = evaluate_model(model, train_loader)\n",
    "\n",
    "label_names = label_encoder.classes_\n",
    "\n",
    "print_cm(true_labels, predictions, label_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
